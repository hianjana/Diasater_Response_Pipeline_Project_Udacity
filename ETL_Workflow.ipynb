{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline\n",
    "\n",
    "The intent of this notebook is to load the 2 files which have disaster response data: messages.csv, categories.csv, clean them, combine them and load it into a SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sections:**\n",
    "1. Load csv files \n",
    "2. Data cleaning\n",
    "3. Data merge\n",
    "4. Load data to SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    '''\n",
    "    This fucntion will load data from CSV files\n",
    "    '''\n",
    "    df = pd.read_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categories_cleaning(categories):\n",
    "    '''\n",
    "    This function will do the following:\n",
    "    Split the values in the categories column on the ; character so that each value becomes a separate column. \n",
    "    Use the first row of categories dataframe to create column names for the categories data.\n",
    "    Rename columns of categories with new column names.\n",
    "    '''\n",
    "    \n",
    "    # create a dataframe of the 36 individual category columns\n",
    "    categories_split = categories['categories'].str.split(';', expand=True)\n",
    "    \n",
    "    # select the first row of the categories dataframe\n",
    "    row = categories_split.iloc[0]\n",
    "    \n",
    "    # use this row to extract a list of new column names for categories\n",
    "    category_colnames = [each[:-2] for each in row]\n",
    "    #print(category_colnames)\n",
    "    \n",
    "    # rename the columns\n",
    "    categories_split.columns = category_colnames\n",
    "          \n",
    "    for column in categories_split:\n",
    "        # set each value to be the last character of the string\n",
    "        categories_split[column] = categories_split[column].apply(lambda x: x[-1:])\n",
    "    \n",
    "        # convert column from string to numeric\n",
    "        categories_split[column] = categories_split[column].astype('int')\n",
    "    \n",
    "    categories_clean = categories.merge(categories_split, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "    # drop the original categories column\n",
    "    categories_clean.drop(['categories'], axis=1,inplace=True)\n",
    "    \n",
    "    return categories_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_merge(messages, categories_clean):\n",
    "    '''\n",
    "    This function will merge the messages and cleaned categories datasets\n",
    "    '''\n",
    "    df = pd.merge(messages, categories_clean,on='id')\n",
    "    \n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load data to SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_into_sql(df, db):\n",
    "    '''\n",
    "    This fucntion will load the datafame to a SQL database\n",
    "    '''\n",
    "    engine = create_engine(db)\n",
    "    df.to_sql('DisasterMessages', engine, index=False)\n",
    "    print('Data load complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    This is the main function which calls all other functions to load data from the CSV files, clean them, merge them and\n",
    "    load it back to a SQL database.\n",
    "    '''\n",
    "    # Load the messages dataset\n",
    "    messages = load_data('messages.csv') \n",
    "    # Load the categories dataset\n",
    "    categories = load_data('categories.csv') \n",
    "    \n",
    "    # clean the categories dataset and split the 'categories' column into individual columns per category\n",
    "    categories_clean = categories_cleaning(categories)\n",
    "    \n",
    "    # Merge the cleaned categories dataset and messages dataset\n",
    "    df = data_merge(messages, categories_clean)\n",
    "    \n",
    "    # Load to a SQL database\n",
    "    load_into_sql(df, 'sqlite:///DisasterMessages.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data load complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
